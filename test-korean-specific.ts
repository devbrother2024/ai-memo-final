// test-korean-specific.ts
// í•œêµ­ì–´ ì²˜ë¦¬ íŠ¹í™” í…ŒìŠ¤íŠ¸

import * as dotenv from 'dotenv'
import { getGeminiClient } from './lib/ai/gemini-client'

// .env.local íŒŒì¼ ë¡œë“œ
dotenv.config({
    path: '/Users/macrent/Desktop/ai-memo-hands-on-story-2.5/.env.local'
})

async function testKoreanProcessing() {
    console.log('ðŸ‡°ðŸ‡· í•œêµ­ì–´ ì²˜ë¦¬ íŠ¹í™” í…ŒìŠ¤íŠ¸ ì‹œìž‘...\n')

    const client = getGeminiClient()

    // 1. ëª…ì‹œì  í•œêµ­ì–´ ì§€ì‹œ
    console.log('1ï¸âƒ£ ëª…ì‹œì  í•œêµ­ì–´ ì§€ì‹œ í…ŒìŠ¤íŠ¸...')
    try {
        const response = await client.generateText({
            prompt: 'í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”. ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì–´ë–¤ê°€ìš”?',
            maxTokens: 100,
            temperature: 0.7
        })

        console.log('í”„ë¡¬í”„íŠ¸: "í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”. ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì–´ë–¤ê°€ìš”?"')
        console.log('ì‘ë‹µ:', response.text)
        console.log('í† í° ì‚¬ìš©ëŸ‰:', response.tokens, '\n')
    } catch (error) {
        console.log('âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨:', error, '\n')
    }

    // 2. ì‹œìŠ¤í…œ ë©”ì‹œì§€ ìŠ¤íƒ€ì¼ë¡œ í•œêµ­ì–´ ê°•ì œ
    console.log('2ï¸âƒ£ ì‹œìŠ¤í…œ ë©”ì‹œì§€ ìŠ¤íƒ€ì¼ í…ŒìŠ¤íŠ¸...')
    try {
        const response = await client.generateText({
            prompt: `ë‹¹ì‹ ì€ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ìž…ë‹ˆë‹¤. 
ì§ˆë¬¸: ê°„ë‹¨í•œ ìžê¸°ì†Œê°œë¥¼ í•´ì£¼ì„¸ìš”.
ë‹µë³€ (í•œêµ­ì–´ë¡œ):`,
            maxTokens: 150,
            temperature: 0.5
        })

        console.log('í”„ë¡¬í”„íŠ¸: ì‹œìŠ¤í…œ ë©”ì‹œì§€ + í•œêµ­ì–´ ê°•ì œ')
        console.log('ì‘ë‹µ:', response.text)
        console.log('í† í° ì‚¬ìš©ëŸ‰:', response.tokens, '\n')
    } catch (error) {
        console.log('âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨:', error, '\n')
    }

    // 3. ì˜ì–´ í”„ë¡¬í”„íŠ¸ë¡œ í•œêµ­ì–´ ìš”ì²­
    console.log('3ï¸âƒ£ ì˜ì–´ í”„ë¡¬í”„íŠ¸ë¡œ í•œêµ­ì–´ ìš”ì²­ í…ŒìŠ¤íŠ¸...')
    try {
        const response = await client.generateText({
            prompt: 'Please respond in Korean. Tell me about your capabilities.',
            maxTokens: 150,
            temperature: 0.7
        })

        console.log(
            'í”„ë¡¬í”„íŠ¸: "Please respond in Korean. Tell me about your capabilities."'
        )
        console.log('ì‘ë‹µ:', response.text)
        console.log('í† í° ì‚¬ìš©ëŸ‰:', response.tokens, '\n')
    } catch (error) {
        console.log('âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨:', error, '\n')
    }

    // 4. ìš”ì•½ í…ŒìŠ¤íŠ¸ (í•œêµ­ì–´ ê°•ì œ)
    console.log('4ï¸âƒ£ í•œêµ­ì–´ ìš”ì•½ í…ŒìŠ¤íŠ¸...')
    try {
        const longText = `
    ì˜¤ëŠ˜ì€ íšŒì‚¬ì—ì„œ ìƒˆë¡œìš´ í”„ë¡œì íŠ¸ í‚¥ì˜¤í”„ ë¯¸íŒ…ì´ ìžˆì—ˆë‹¤. 
    AI ê¸°ë°˜ ë©”ëª¨ ì•±ì„ ê°œë°œí•˜ëŠ” í”„ë¡œì íŠ¸ë¡œ, Reactì™€ TypeScriptë¥¼ ì‚¬ìš©í•œë‹¤.
    ë°±ì—”ë“œëŠ” Supabaseë¥¼ í™œìš©í•˜ê³ , AI APIëŠ” Google Geminië¥¼ ì—°ë™í•  ì˜ˆì •ì´ë‹¤.
    íŒ€ì›ë“¤ê³¼ ê¸°ìˆ  ìŠ¤íƒê³¼ ì¼ì •ì„ ë…¼ì˜í–ˆê³ , 2ì£¼ ì•ˆì— MVPë¥¼ ì™„ì„±í•˜ê¸°ë¡œ í–ˆë‹¤.
    ê°œë°œ ê³¼ì •ì—ì„œ ì‚¬ìš©ìž í”¼ë“œë°±ì„ ì ê·¹ ë°˜ì˜í•  ê³„íšì´ë‹¤.
    `

        const response = await client.generateText({
            prompt: `ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ 2-3ë¬¸ìž¥ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”:

${longText}

ìš”ì•½ (í•œêµ­ì–´):`,
            maxTokens: 200,
            temperature: 0.3
        })

        console.log('ìš”ì•½ ëŒ€ìƒ í…ìŠ¤íŠ¸ ê¸¸ì´:', longText.trim().length, 'ìž')
        console.log('ìš”ì•½ ê²°ê³¼:', response.text)
        console.log('í† í° ì‚¬ìš©ëŸ‰:', response.tokens, '\n')
    } catch (error) {
        console.log('âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨:', error, '\n')
    }

    // 5. íƒœê·¸ ìƒì„± í…ŒìŠ¤íŠ¸ (í•œêµ­ì–´)
    console.log('5ï¸âƒ£ í•œêµ­ì–´ íƒœê·¸ ìƒì„± í…ŒìŠ¤íŠ¸...')
    try {
        const noteContent = `
    ìƒˆë¡œìš´ React í”„ë¡œì íŠ¸ ì‹œìž‘
    - Next.js 14 ì‚¬ìš©
    - TypeScript ì ìš©
    - Tailwind CSS ìŠ¤íƒ€ì¼ë§
    - Supabase ë°±ì—”ë“œ
    - Vercel ë°°í¬ ì˜ˆì •
    `

        const response = await client.generateText({
            prompt: `ë‹¤ìŒ ë…¸íŠ¸ì˜ í•µì‹¬ í‚¤ì›Œë“œë¥¼ í•œêµ­ì–´ë¡œ 3-5ê°œ ì¶”ì¶œí•´ì£¼ì„¸ìš”. ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ë‚˜ì—´í•´ì£¼ì„¸ìš”:

${noteContent}

í‚¤ì›Œë“œ (í•œêµ­ì–´):`,
            maxTokens: 100,
            temperature: 0.3
        })

        console.log('ë…¸íŠ¸ ë‚´ìš©:', noteContent.trim())
        console.log('ì¶”ì¶œëœ í‚¤ì›Œë“œ:', response.text)
        console.log('í† í° ì‚¬ìš©ëŸ‰:', response.tokens, '\n')
    } catch (error) {
        console.log('âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨:', error, '\n')
    }

    // 6. ë‹¤ì–‘í•œ ì˜¨ë„ ì„¤ì • í…ŒìŠ¤íŠ¸
    console.log('6ï¸âƒ£ ì˜¨ë„ë³„ ì‘ë‹µ ì°¨ì´ í…ŒìŠ¤íŠ¸...')
    const temperatures = [0.1, 0.5, 0.9]

    for (const temp of temperatures) {
        try {
            const response = await client.generateText({
                prompt: 'í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”. ì°½ì˜ì ì¸ ì•± ì•„ì´ë””ì–´ í•˜ë‚˜ë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”.',
                maxTokens: 100,
                temperature: temp
            })

            console.log(
                `ì˜¨ë„ ${temp}:`,
                response.text.substring(0, 100) + '...'
            )
        } catch (error) {
            console.log(`âŒ ì˜¨ë„ ${temp} í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨:`, error)
        }
    }

    console.log('\nðŸŽ‰ í•œêµ­ì–´ íŠ¹í™” í…ŒìŠ¤íŠ¸ ì™„ë£Œ!')
}

// ì‹¤í–‰
testKoreanProcessing().catch(error => {
    console.error('í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜:', error)
    process.exit(1)
})
